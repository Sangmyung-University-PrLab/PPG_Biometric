{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf424321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statsmodels.stats import weightstats as stests\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda, Bidirectional,Dropout,BatchNormalization,Flatten, GRU, MaxPool1D\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d650b3-84f5-4a0d-b7e2-52c6e1695f23",
   "metadata": {},
   "source": [
    "### 트레인셋 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db42e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= []\n",
    "Y_ = []\n",
    "\n",
    "f = open(\"train_data_4.csv\" , 'r')\n",
    "X = list(csv.reader(f, quoting = csv.QUOTE_NONNUMERIC))\n",
    "X = np.array(X)\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = open(\"train_label_0.csv\" , 'r')\n",
    "Y_ = list(csv.reader(f, quoting = csv.QUOTE_NONNUMERIC))\n",
    "Y_ = np.array(Y_)\n",
    "Y_ = Y_.T\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6cb08c-d091-4c02-81c3-4af57f7a657d",
   "metadata": {},
   "source": [
    "### 테스트셋 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6cc89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = []\n",
    "YY_ = []\n",
    "\n",
    "\n",
    "f = open(\"test_data_4.csv\" , 'r')\n",
    "XX = list(csv.reader(f, quoting = csv.QUOTE_NONNUMERIC))\n",
    "XX = np.array(XX)\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = open(\"test_label_0.csv\" , 'r')\n",
    "YY_ = list(csv.reader(f, quoting = csv.QUOTE_NONNUMERIC))\n",
    "YY_ = np.array(YY_)\n",
    "YY_ = YY_.T\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04593f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 7.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [12.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [15.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [16.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [17.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [18.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [19.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [20.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [21.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [22.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [23.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [24.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [25.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [26.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [27.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [28.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [29.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [30.],\n",
       "       [31.],\n",
       "       [31.],\n",
       "       [31.],\n",
       "       [31.],\n",
       "       [31.],\n",
       "       [31.],\n",
       "       [31.],\n",
       "       [31.],\n",
       "       [31.],\n",
       "       [31.],\n",
       "       [31.],\n",
       "       [31.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [32.],\n",
       "       [33.],\n",
       "       [33.],\n",
       "       [33.],\n",
       "       [33.],\n",
       "       [33.],\n",
       "       [33.],\n",
       "       [33.],\n",
       "       [33.],\n",
       "       [33.],\n",
       "       [33.],\n",
       "       [33.],\n",
       "       [33.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [34.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa2cd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1374, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c82ea7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(YY_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64460006",
   "metadata": {},
   "source": [
    "### 라벨 이진화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a39cd189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#트레인 라벨\n",
    "Y = []\n",
    "for i in range(1,36):    \n",
    "    label = []\n",
    "    for j in range(0,len(Y_)):\n",
    "        if Y_[j] == i:\n",
    "            label.append(1)\n",
    "        if Y_[j] != i:\n",
    "            label.append(0)\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb57b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd3b3a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 라벨\n",
    "YY = []\n",
    "for i in range(1,36):    \n",
    "    label = []\n",
    "    for j in range(0,len(YY_)):\n",
    "        if YY_[j] == i:\n",
    "            label.append(1)\n",
    "        if YY_[j] != i:\n",
    "            label.append(0)\n",
    "\n",
    "    YY.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85d41ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)\n",
    "np.shape(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e7f0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = np.reshape(XX,(700, 50,1) )\n",
    "XX = XX.tolist()\n",
    "\n",
    "X = np.reshape(X,(1374, 50,1) )\n",
    "X = X.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00512b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1374, 50, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee57811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b78832",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "YY_ = tf.keras.utils.to_categorical(YY_, num_classes=36) \n",
    "Y_ = tf.keras.utils.to_categorical(Y_, num_classes=36) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ed8e78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 36)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(YY_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b8aa729",
   "metadata": {},
   "outputs": [],
   "source": [
    "YY_ = YY_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "257adf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ = Y_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b2f371",
   "metadata": {},
   "source": [
    "## 1d cnn test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a50d4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # 1차원 feature map 생성\n",
    "    \n",
    "    Conv1D(filters=16, kernel_size=5,\n",
    "           activation=\"relu\"),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv1D(filters=32, kernel_size=3,\n",
    "           activation=\"relu\"),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv1D(filters=64, kernel_size=3,\n",
    "           activation=\"relu\"),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(36, activation=\"softmax\"),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1a1d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(0.001)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f76e2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "# val_loss 기준 체크포인터도 생성합니다.\n",
    "filename = os.path.join('tmp', 'ckeckpointer.ckpt')\n",
    "checkpoint = ModelCheckpoint(filename, \n",
    "                             save_weights_only=True, \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6741341c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1374, 36)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ae041e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "35/43 [=======================>......] - ETA: 0s - loss: 2.9319 - acc: 0.2000WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 1s 3ms/step - loss: 2.8067 - acc: 0.2351\n",
      "Epoch 2/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 1.8675 - acc: 0.5032WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8478 - acc: 0.5051\n",
      "Epoch 3/80\n",
      "36/43 [========================>.....] - ETA: 0s - loss: 1.4571 - acc: 0.6259WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4312 - acc: 0.6354\n",
      "Epoch 4/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 1.1560 - acc: 0.7067WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1441 - acc: 0.7052\n",
      "Epoch 5/80\n",
      "36/43 [========================>.....] - ETA: 0s - loss: 0.9749 - acc: 0.7517WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9516 - acc: 0.7635\n",
      "Epoch 6/80\n",
      "35/43 [=======================>......] - ETA: 0s - loss: 0.8154 - acc: 0.7884WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.8194 - acc: 0.7817\n",
      "Epoch 7/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.6944 - acc: 0.8461WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7038 - acc: 0.8443\n",
      "Epoch 8/80\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.6423 - acc: 0.8294WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6504 - acc: 0.8217\n",
      "Epoch 9/80\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.5893 - acc: 0.8505WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5721 - acc: 0.8515\n",
      "Epoch 10/80\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.5212 - acc: 0.8598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5070 - acc: 0.8661\n",
      "Epoch 11/80\n",
      "35/43 [=======================>......] - ETA: 0s - loss: 0.4298 - acc: 0.9018WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4354 - acc: 0.8988\n",
      "Epoch 12/80\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.4262 - acc: 0.8936WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4274 - acc: 0.8901\n",
      "Epoch 13/80\n",
      "38/43 [=========================>....] - ETA: 0s - loss: 0.4174 - acc: 0.8890WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4152 - acc: 0.8908\n",
      "Epoch 14/80\n",
      "38/43 [=========================>....] - ETA: 0s - loss: 0.3724 - acc: 0.9005WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3595 - acc: 0.9076\n",
      "Epoch 15/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.3398 - acc: 0.9191WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3250 - acc: 0.9250\n",
      "Epoch 16/80\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.2954 - acc: 0.9358WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3108 - acc: 0.9301\n",
      "Epoch 17/80\n",
      "38/43 [=========================>....] - ETA: 0s - loss: 0.3065 - acc: 0.9252WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2986 - acc: 0.9265\n",
      "Epoch 18/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.2697 - acc: 0.9383WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2719 - acc: 0.9374\n",
      "Epoch 19/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.2536 - acc: 0.9367WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2565 - acc: 0.9352\n",
      "Epoch 20/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.2733 - acc: 0.9231WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2646 - acc: 0.9272\n",
      "Epoch 21/80\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.2154 - acc: 0.9426WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2194 - acc: 0.9410\n",
      "Epoch 22/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.2068 - acc: 0.9555WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2055 - acc: 0.9556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.1885 - acc: 0.9596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1872 - acc: 0.9592\n",
      "Epoch 24/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.2013 - acc: 0.9482WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2004 - acc: 0.9483\n",
      "Epoch 25/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.1660 - acc: 0.9588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1665 - acc: 0.9578\n",
      "Epoch 26/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.1659 - acc: 0.9566WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1642 - acc: 0.9578\n",
      "Epoch 27/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.1571 - acc: 0.9602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1571 - acc: 0.9600\n",
      "Epoch 28/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.1411 - acc: 0.9680WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1435 - acc: 0.9658\n",
      "Epoch 29/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.1661 - acc: 0.9516WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1694 - acc: 0.9505\n",
      "Epoch 30/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.1493 - acc: 0.9594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1510 - acc: 0.9592\n",
      "Epoch 31/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.1275 - acc: 0.9695WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1250 - acc: 0.9702\n",
      "Epoch 32/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.1271 - acc: 0.9727WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1264 - acc: 0.9731\n",
      "Epoch 33/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.1217 - acc: 0.9656WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1229 - acc: 0.9651\n",
      "Epoch 34/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.1101 - acc: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1097 - acc: 0.9753\n",
      "Epoch 35/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.1146 - acc: 0.9726WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1129 - acc: 0.9738\n",
      "Epoch 36/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.1031 - acc: 0.9784WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1035 - acc: 0.9774\n",
      "Epoch 37/80\n",
      "38/43 [=========================>....] - ETA: 0s - loss: 0.1072 - acc: 0.9704WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1039 - acc: 0.9731\n",
      "Epoch 38/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0943 - acc: 0.9718WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0967 - acc: 0.9716\n",
      "Epoch 39/80\n",
      "35/43 [=======================>......] - ETA: 0s - loss: 0.0929 - acc: 0.9723WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1010 - acc: 0.9702\n",
      "Epoch 40/80\n",
      "35/43 [=======================>......] - ETA: 0s - loss: 0.0897 - acc: 0.9777WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0869 - acc: 0.9782\n",
      "Epoch 41/80\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.0764 - acc: 0.9873WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0814 - acc: 0.9840\n",
      "Epoch 42/80\n",
      "35/43 [=======================>......] - ETA: 0s - loss: 0.0794 - acc: 0.9804WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0829 - acc: 0.9774\n",
      "Epoch 43/80\n",
      "36/43 [========================>.....] - ETA: 0s - loss: 0.0827 - acc: 0.9809WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0847 - acc: 0.9796\n",
      "Epoch 44/80\n",
      "36/43 [========================>.....] - ETA: 0s - loss: 0.0848 - acc: 0.9800WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0807 - acc: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.0683 - acc: 0.9872WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0671 - acc: 0.9876\n",
      "Epoch 46/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0667 - acc: 0.9875WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0656 - acc: 0.9884\n",
      "Epoch 47/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0604 - acc: 0.9867WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0617 - acc: 0.9862\n",
      "Epoch 48/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0663 - acc: 0.9840WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0650 - acc: 0.9847\n",
      "Epoch 49/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0599 - acc: 0.9909WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0585 - acc: 0.9913\n",
      "Epoch 50/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0535 - acc: 0.9914WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0538 - acc: 0.9913\n",
      "Epoch 51/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0577 - acc: 0.9898WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0578 - acc: 0.9891\n",
      "Epoch 52/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0576 - acc: 0.9875WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0597 - acc: 0.9862\n",
      "Epoch 53/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0656 - acc: 0.9832WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0657 - acc: 0.9833\n",
      "Epoch 54/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0616 - acc: 0.9867WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0612 - acc: 0.9869\n",
      "Epoch 55/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.0524 - acc: 0.9888WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0563 - acc: 0.9869\n",
      "Epoch 56/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0543 - acc: 0.9875WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0536 - acc: 0.9876\n",
      "Epoch 57/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0522 - acc: 0.9883WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0536 - acc: 0.9884\n",
      "Epoch 58/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0438 - acc: 0.9947WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0430 - acc: 0.9949\n",
      "Epoch 59/80\n",
      "36/43 [========================>.....] - ETA: 0s - loss: 0.0496 - acc: 0.9905WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0521 - acc: 0.9876\n",
      "Epoch 60/80\n",
      "32/43 [=====================>........] - ETA: 0s - loss: 0.0408 - acc: 0.9941WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0426 - acc: 0.9934\n",
      "Epoch 61/80\n",
      "38/43 [=========================>....] - ETA: 0s - loss: 0.0610 - acc: 0.9844WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0584 - acc: 0.9854\n",
      "Epoch 62/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.0431 - acc: 0.9912WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0433 - acc: 0.9913\n",
      "Epoch 63/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.0386 - acc: 0.9920WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0402 - acc: 0.9913\n",
      "Epoch 64/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.0351 - acc: 0.9928WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0336 - acc: 0.9934\n",
      "Epoch 65/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0366 - acc: 0.9906WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0368 - acc: 0.9905\n",
      "Epoch 66/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.0293 - acc: 0.9960WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0296 - acc: 0.9956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/80\n",
      "38/43 [=========================>....] - ETA: 0s - loss: 0.0368 - acc: 0.9893WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0395 - acc: 0.9891\n",
      "Epoch 68/80\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.0372 - acc: 0.9924WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0385 - acc: 0.9920\n",
      "Epoch 69/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0377 - acc: 0.9961WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0368 - acc: 0.9964\n",
      "Epoch 70/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0333 - acc: 0.9931WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0338 - acc: 0.9934\n",
      "Epoch 71/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0342 - acc: 0.9954WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0342 - acc: 0.9956\n",
      "Epoch 72/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0287 - acc: 0.9947WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0286 - acc: 0.9949\n",
      "Epoch 73/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0306 - acc: 0.9954WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0298 - acc: 0.9956\n",
      "Epoch 74/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0233 - acc: 0.9984WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0229 - acc: 0.9985\n",
      "Epoch 75/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.0171 - acc: 0.9992WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0185 - acc: 0.9985\n",
      "Epoch 76/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.0212 - acc: 0.9968WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0220 - acc: 0.9964\n",
      "Epoch 77/80\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0214 - acc: 0.9962WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0216 - acc: 0.9964\n",
      "Epoch 78/80\n",
      "38/43 [=========================>....] - ETA: 0s - loss: 0.0246 - acc: 0.9967WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0240 - acc: 0.9964\n",
      "Epoch 79/80\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.0209 - acc: 0.9984WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0198 - acc: 0.9985\n",
      "Epoch 80/80\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0178 - acc: 0.9977WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0178 - acc: 0.9978\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = X,\n",
    "                    y = Y_,\n",
    "                    epochs=80, \n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86cc2e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 46, 16)            96        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 23, 16)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 23, 16)           64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 21, 32)            1568      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 10, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 64)             6208      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 64)            256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 36)                9252      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,572\n",
      "Trainable params: 17,348\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9a618bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step\n",
      "(700, 36)\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2041 - acc: 0.9600\n",
      "\n",
      " 테스트 정확도: 0.9600\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(XX)\n",
    "print(pred.shape)\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(XX, YY_)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e914f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 9))\n",
    "# plt.plot(np.asarray(YY_), label='actual')\n",
    "# plt.plot(pred, label='prediction')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "392afed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis(history,name) :\n",
    "    plt.title(f\"{name.upper()}\")\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(f\"{name.lower()}\")\n",
    "    value = history.history.get(name)\n",
    "    val_value = history.history.get(f\"val_{name}\",None)\n",
    "    epochs = range(1, len(value)+1)\n",
    "    plt.plot(epochs, value, 'b-', label=f'training {name}')\n",
    "    if val_value is not None :\n",
    "        plt.plot(epochs, val_value, 'r:', label=f'validation {name}')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.05, 1.2) , fontsize=10 , ncol=1)\n",
    "    \n",
    "def plot_history(history) :\n",
    "    key_value = list(set([i.split(\"val_\")[-1] for i in list(history.history.keys())]))\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for idx , key in enumerate(key_value) :\n",
    "        plt.subplot(1, len(key_value), idx+1)\n",
    "        vis(history, key)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2adb99ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70b82027",
   "metadata": {},
   "outputs": [],
   "source": [
    "YY_ = tf.math.argmax(YY_,axis = 1)\n",
    "pred = tf.math.argmax(pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e696eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./ppg_96_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114ce75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c00169d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.97      0.97        31\n",
      "           2       0.91      0.80      0.85        25\n",
      "           3       0.71      1.00      0.83        15\n",
      "           4       0.84      0.89      0.86        18\n",
      "           5       1.00      0.95      0.98        22\n",
      "           6       1.00      1.00      1.00        17\n",
      "           7       0.83      0.87      0.85        23\n",
      "           8       0.97      1.00      0.98        30\n",
      "           9       1.00      0.97      0.98        30\n",
      "          10       0.89      1.00      0.94        16\n",
      "          11       0.96      1.00      0.98        24\n",
      "          12       1.00      0.91      0.95        23\n",
      "          13       1.00      1.00      1.00        26\n",
      "          14       1.00      1.00      1.00        22\n",
      "          15       1.00      0.96      0.98        28\n",
      "          16       0.96      1.00      0.98        23\n",
      "          17       1.00      1.00      1.00        20\n",
      "          18       0.88      1.00      0.93        14\n",
      "          19       1.00      1.00      1.00        17\n",
      "          20       1.00      1.00      1.00        22\n",
      "          21       1.00      1.00      1.00        20\n",
      "          22       1.00      1.00      1.00        13\n",
      "          23       1.00      0.87      0.93        15\n",
      "          24       0.85      1.00      0.92        22\n",
      "          25       1.00      1.00      1.00        20\n",
      "          26       1.00      1.00      1.00        20\n",
      "          27       1.00      1.00      1.00        18\n",
      "          28       1.00      1.00      1.00        18\n",
      "          29       0.93      0.81      0.87        16\n",
      "          30       1.00      0.88      0.93        16\n",
      "          31       1.00      0.75      0.86        12\n",
      "          32       1.00      0.94      0.97        18\n",
      "          33       1.00      1.00      1.00        12\n",
      "          34       1.00      0.95      0.97        19\n",
      "          35       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.96       700\n",
      "   macro avg       0.96      0.96      0.96       700\n",
      "weighted avg       0.96      0.96      0.96       700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(YY_, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppgbio_1",
   "language": "python",
   "name": "ppgbio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
